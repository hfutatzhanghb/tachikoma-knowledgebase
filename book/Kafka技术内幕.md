- [1] Kafka的功能
  - 数据注入 (事件的发布和订阅)
    - 队列模式: 每个消息只发送给一个消费者
    - 发布/订阅模式: 每个消息发布给所有的消费者
  - 数据存储 (存储节点的故障容错)
  - 流处理 (聚合/连接/转换/...)
- [3] 分区模型
  - 一个主题对应多个分区, 分区的偏移量独自维护
  - [62] 一个分区只能被消费组中一个消费者所消费
    - 一个消费组中, 一个消费者可以同时消费多个分区
    - 一个消费组中, 不同消费者一定消费不同分区
  - [65] 分区的消费进度: 虽然是 消费者 消费分区, 但进度是以 消费者组 进行保存, 以便再平衡
- [5] 清理策略
  - 消费完清理, 则需跟踪消费状态
  - 按时间清理 (Kafka)
- [5] 分布式模型
  - Leader负责所有读写
  - Follower仅做数据冗余
- [9] 生产者/消费者的通信模型
  - 推
    - 需处理不同消费者之间的速度差
    - 需可信的进行 元信息 持久化
  - 拉 (Kafka)
    - 轮询成本高 -> 使用长阻塞式通信
- [11] 消息冗余: 消息多写到ISR集合 (数据同步的节点集合) 后, 才认为被提交
- [35-42] NIO代码样例详解 (推荐)
- [214][290] 消费者加入集群的协调过程: 
  1. 消费者->协调者: 加入组请求
  2. 协调者: 收集 所有消费者的信息
  3. 协调者->主消费者: 加入组响应+所有消费者的信息. 主消费者需执行任务分配算法, 将不同分区分配给不同消费者 (减少协调者负担??)
  4. 主消费者->协调者: 同步组请求. 协调者 持久化 消费组的分配结果.
  5. 协调者->消费者: 同步组响应. 返回分配结果.
- [244] 延迟操作
  - 一类特殊的操作, 有特别的执行机制. 操作特点: 无法即时完成, 需等待某条件满足或超时
  - 类似于 条件变量
- [295] 副本
  - 一个分区有多个副本
  - 一个副本对应一个日志, 对应多个日志分段 (rotate/回收)
  - 副本的集合
    - AR (Assigned Replica): 所有副本的集合
    - ISR (In-Sync Replica): 与主副本同步的副本的集合
  - [370] 副本的管理
    - 偏移量(LEO): 有多少日志
    - 水位线(HW): ISR中最少应有多少日志, 以决定是否副本能加入ISR
- [333] 日志的刷盘策略: 按时间/按大小
- [336] 日志的压缩
  - k-v形式只保留同一个k的最新值
  - 日志清理: 使用同一片空间, 分段压缩 (???)
  - [340] 日志 -> 清理(去除旧记录) -> 压缩(日志文件合并) -> 删除(旧日志文件)
- [397] 数据结构: 时间轮 (定时器)
  - 对快到期的时间, 放在第一层时间轮中, 细粒度进行处理
  - 对较远到期的时间, 放在高层的时间轮中, 粗粒度进行处理, 快到期时, 再展开到第一层时间轮中
- [403] 控制器通过ZK选主
- [490] 集群同步工具
  - MirrowMaker: 多消费者, 单生产者
  - uReplicator = Helix + MirrorMaker
  - Kafka consumer
- [575] 流数据的处理方式
  - 逐条处理: Storm, Kafka
  - 小批次处理 (micro-batch): Spark Streaming

